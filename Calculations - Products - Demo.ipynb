{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de5ef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date commandé</th>\n",
       "      <th>No de commande</th>\n",
       "      <th>E-mail</th>\n",
       "      <th>Adresse (Livraison)</th>\n",
       "      <th>Code postal (Livraison)</th>\n",
       "      <th>Ville (Livraison)</th>\n",
       "      <th>Point de collecte</th>\n",
       "      <th>ID point de collecte</th>\n",
       "      <th>Total payé</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Nom du produit</th>\n",
       "      <th>Categorie</th>\n",
       "      <th>Quantité</th>\n",
       "      <th>Prix du produit</th>\n",
       "      <th>Code de coupon</th>\n",
       "      <th>Réduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346180</td>\n",
       "      <td>2020-03-29 16:44:04</td>\n",
       "      <td>664</td>\n",
       "      <td>0</td>\n",
       "      <td>1-5365 16e Avenue</td>\n",
       "      <td>H1X 2S3</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.84</td>\n",
       "      <td>PQ0211</td>\n",
       "      <td>Grand Panier</td>\n",
       "      <td>Panier,Panier principal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>346179</td>\n",
       "      <td>2020-03-30 10:23:53</td>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "      <td>1240 Beaubien Est</td>\n",
       "      <td>H2S 1T7</td>\n",
       "      <td>Montréak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.12</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>346178</td>\n",
       "      <td>2020-03-30 10:55:52</td>\n",
       "      <td>666</td>\n",
       "      <td>2</td>\n",
       "      <td>5880 de bordeaux</td>\n",
       "      <td>H2G 2R4</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.12</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>346177</td>\n",
       "      <td>2020-03-30 11:19:59</td>\n",
       "      <td>667</td>\n",
       "      <td>3</td>\n",
       "      <td>5257 Rue Fabre</td>\n",
       "      <td>H2J 3W6</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.84</td>\n",
       "      <td>pourboire-01</td>\n",
       "      <td>Pourboire</td>\n",
       "      <td>Non classé</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>346176</td>\n",
       "      <td>2020-03-30 11:19:59</td>\n",
       "      <td>667</td>\n",
       "      <td>3</td>\n",
       "      <td>5257 Rue Fabre</td>\n",
       "      <td>H2J 3W6</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.84</td>\n",
       "      <td>PQ0211</td>\n",
       "      <td>Grand Panier</td>\n",
       "      <td>Panier,Panier principal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338278</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-03-21 22:28:27</td>\n",
       "      <td>51727</td>\n",
       "      <td>3915</td>\n",
       "      <td>5638 Avenue De Lorimier</td>\n",
       "      <td>H2G 2N6</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.75</td>\n",
       "      <td>PQ0552</td>\n",
       "      <td>Zucchinis</td>\n",
       "      <td>Produit unité,Légumes,Zucchinis, piments et au...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338279</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-21 22:28:27</td>\n",
       "      <td>51727</td>\n",
       "      <td>3915</td>\n",
       "      <td>5638 Avenue De Lorimier</td>\n",
       "      <td>H2G 2N6</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.75</td>\n",
       "      <td>PQ0344</td>\n",
       "      <td>Fèves vertes</td>\n",
       "      <td>Produit unité,Légumes,Fèves, poireaux et artic...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338280</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-03-21 22:28:27</td>\n",
       "      <td>51727</td>\n",
       "      <td>3915</td>\n",
       "      <td>5638 Avenue De Lorimier</td>\n",
       "      <td>H2G 2N6</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.75</td>\n",
       "      <td>PQ0555</td>\n",
       "      <td>Concombre anglais</td>\n",
       "      <td>Produit unité,Légumes,Tomates, concombres et a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338281</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-21 22:28:27</td>\n",
       "      <td>51727</td>\n",
       "      <td>3915</td>\n",
       "      <td>5638 Avenue De Lorimier</td>\n",
       "      <td>H2G 2N6</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.75</td>\n",
       "      <td>PQ0499</td>\n",
       "      <td>Tomates classique</td>\n",
       "      <td>Produit unité,Légumes,Tomates, concombres et a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338282</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-21 22:28:27</td>\n",
       "      <td>51727</td>\n",
       "      <td>3915</td>\n",
       "      <td>5638 Avenue De Lorimier</td>\n",
       "      <td>H2G 2N6</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.75</td>\n",
       "      <td>PQ0367</td>\n",
       "      <td>Tarte au sirop d'érable</td>\n",
       "      <td>Produit unité,Boulangerie et Pâtisserie,Tartes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338283 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index        Date commandé  No de commande  E-mail  \\\n",
       "0       346180  2020-03-29 16:44:04             664       0   \n",
       "1       346179  2020-03-30 10:23:53             665       1   \n",
       "2       346178  2020-03-30 10:55:52             666       2   \n",
       "3       346177  2020-03-30 11:19:59             667       3   \n",
       "4       346176  2020-03-30 11:19:59             667       3   \n",
       "...        ...                  ...             ...     ...   \n",
       "338278       4  2022-03-21 22:28:27           51727    3915   \n",
       "338279       3  2022-03-21 22:28:27           51727    3915   \n",
       "338280       2  2022-03-21 22:28:27           51727    3915   \n",
       "338281       1  2022-03-21 22:28:27           51727    3915   \n",
       "338282       0  2022-03-21 22:28:27           51727    3915   \n",
       "\n",
       "            Adresse (Livraison) Code postal (Livraison) Ville (Livraison)  \\\n",
       "0             1-5365 16e Avenue                 H1X 2S3          Montreal   \n",
       "1             1240 Beaubien Est                 H2S 1T7          Montréak   \n",
       "2              5880 de bordeaux                 H2G 2R4          Montréal   \n",
       "3                5257 Rue Fabre                 H2J 3W6          Montreal   \n",
       "4                5257 Rue Fabre                 H2J 3W6          Montreal   \n",
       "...                         ...                     ...               ...   \n",
       "338278  5638 Avenue De Lorimier                 H2G 2N6          Montréal   \n",
       "338279  5638 Avenue De Lorimier                 H2G 2N6          Montréal   \n",
       "338280  5638 Avenue De Lorimier                 H2G 2N6          Montréal   \n",
       "338281  5638 Avenue De Lorimier                 H2G 2N6          Montréal   \n",
       "338282  5638 Avenue De Lorimier                 H2G 2N6          Montréal   \n",
       "\n",
       "       Point de collecte ID point de collecte  Total payé           SKU  \\\n",
       "0                    NaN                  NaN       43.84        PQ0211   \n",
       "1                    NaN                  NaN       34.12         False   \n",
       "2                    NaN                  NaN       34.12         False   \n",
       "3                    NaN                  NaN       49.84  pourboire-01   \n",
       "4                    NaN                  NaN       49.84        PQ0211   \n",
       "...                  ...                  ...         ...           ...   \n",
       "338278               NaN                  NaN      190.75        PQ0552   \n",
       "338279               NaN                  NaN      190.75        PQ0344   \n",
       "338280               NaN                  NaN      190.75        PQ0555   \n",
       "338281               NaN                  NaN      190.75        PQ0499   \n",
       "338282               NaN                  NaN      190.75        PQ0367   \n",
       "\n",
       "                 Nom du produit  \\\n",
       "0                  Grand Panier   \n",
       "1                           NaN   \n",
       "2                           NaN   \n",
       "3                     Pourboire   \n",
       "4                  Grand Panier   \n",
       "...                         ...   \n",
       "338278                Zucchinis   \n",
       "338279             Fèves vertes   \n",
       "338280        Concombre anglais   \n",
       "338281        Tomates classique   \n",
       "338282  Tarte au sirop d'érable   \n",
       "\n",
       "                                                Categorie  Quantité  \\\n",
       "0                                 Panier,Panier principal       1.0   \n",
       "1                                                     NaN       1.0   \n",
       "2                                                     NaN       1.0   \n",
       "3                                              Non classé       1.0   \n",
       "4                                 Panier,Panier principal       1.0   \n",
       "...                                                   ...       ...   \n",
       "338278  Produit unité,Légumes,Zucchinis, piments et au...       1.0   \n",
       "338279  Produit unité,Légumes,Fèves, poireaux et artic...       1.0   \n",
       "338280  Produit unité,Légumes,Tomates, concombres et a...       1.0   \n",
       "338281  Produit unité,Légumes,Tomates, concombres et a...       1.0   \n",
       "338282     Produit unité,Boulangerie et Pâtisserie,Tartes       1.0   \n",
       "\n",
       "        Prix du produit Code de coupon  Réduction  \n",
       "0                 40.00            NaN        NaN  \n",
       "1                 30.00            NaN        NaN  \n",
       "2                 30.00            NaN        NaN  \n",
       "3                  6.00            NaN        NaN  \n",
       "4                 40.00            NaN        NaN  \n",
       "...                 ...            ...        ...  \n",
       "338278             6.95            NaN        NaN  \n",
       "338279             3.95            NaN        NaN  \n",
       "338280             2.75            NaN        NaN  \n",
       "338281             4.50            NaN        NaN  \n",
       "338282            13.25            NaN        NaN  \n",
       "\n",
       "[338283 rows x 17 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"Commandes 2020-03-29_2022-03-21.xlsx\")\n",
    "\n",
    "#first we have to remove all employee orders, we can drop rows with employee emails (these were provided to me).\n",
    "#NOTE!!! To preserve employee privacy, I have left out several lines in this version, one for each employee.\n",
    "df.drop(index=df[df['E-mail'] == 'john.smith@example.com'].index, inplace=True) #This is an example!\n",
    "\n",
    "#we flip the data so that the date is in ascending order and reset the index\n",
    "df = df.reindex(index=df.index[::-1])\n",
    "df = df.reset_index()\n",
    "df['E-mail'] = pd.factorize(df['E-mail'])[0]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e77245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver\\AppData\\Local\\Temp/ipykernel_8368/1008441364.py:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  categories =  pd.get_dummies(df['Categorie'].explode()).sum(level=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vegetables', 'Fruits', 'Fish and Seafood', 'Meat and charcuterie', 'Bread and baked goods', 'Dairy and Cheese Products', 'Prepared Meals and Dips', 'Plants, Flowers and Garden', 'Pantry/Groceries', 'Snacks', 'Bulk', 'Other products', 'Drinks', 'Baskets/Paniers', 'Beauty and Body Products', 'Eggs', 'Honey, Syrups, Jams, Nut Butters', 'Household Products']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#In the above data frame we can see that the item categories are sort of hierarchical - Oeufs are inside Epiceries which are\n",
    "#inside Produit Unite.\n",
    "#We will do some heavy duty data cleaning to reduce and clarify product categories.\n",
    "#some deciciouns here will be obvious (e.g. citrus in fruit) but some will\n",
    "#be a bit editorial (e.g. should oil and vinager be a category - I said no). Keeping in mind that the company is focused\n",
    "#on sales from Jean Talon market\n",
    "categories =  pd.get_dummies(df['Categorie'].explode()).sum(level=0)\n",
    "categories\n",
    "\n",
    "\n",
    "categories['Vegetables'] = categories['Produit unité,Légumes'] + categories['Produit unité,Légumes,Ail et oignons'] + categories['Produit unité,Légumes,Anti-gaspillage']\\\n",
    "+ categories['Produit unité,Légumes,Brocolis, choux, céleris et asperges'] + categories['Produit unité,Légumes,Brocolis, choux, céleris et asperges,Anti-gaspillage']\\\n",
    "+ categories['Produit unité,Légumes,Champignons'] + categories['Produit unité,Légumes,Citrouilles et courges'] + categories['Produit unité,Légumes,Fines herbes']\\\n",
    "+ categories['Produit unité,Légumes,Fèves, poireaux et artichauts'] + categories['Produit unité,Légumes,Laitues et pousses'] + categories['Produit unité,Légumes,Laitues et pousses,Anti-gaspillage']\\\n",
    "+ categories['Produit unité,Légumes,Légumes-racines'] + categories['Produit unité,Légumes,Pommes de terre et autres tubercules'] + categories['Produit unité,Légumes,Pommes de terre et autres tubercules,Anti-gaspillage']\\\n",
    "+ categories['Produit unité,Légumes,Tomates, concombres et avocats'] + categories['Produit unité,Légumes,Tomates, concombres et avocats,Anti-gaspillage'] + categories['Produit unité,Légumes,Zucchinis, piments et aubergines']\\\n",
    "+ categories['Produit unité,Légumes,Zucchinis, piments et aubergines,Anti-gaspillage']\n",
    "categories = categories.drop(columns=['Produit unité,Légumes', 'Produit unité,Légumes,Ail et oignons', 'Produit unité,Légumes,Anti-gaspillage', 'Produit unité,Légumes,Brocolis, choux, céleris et asperges',\n",
    "                                     'Produit unité,Légumes,Brocolis, choux, céleris et asperges,Anti-gaspillage', 'Produit unité,Légumes,Champignons', 'Produit unité,Légumes,Citrouilles et courges', 'Produit unité,Légumes,Fines herbes',\n",
    "                                     'Produit unité,Légumes,Fèves, poireaux et artichauts', 'Produit unité,Légumes,Laitues et pousses', 'Produit unité,Légumes,Laitues et pousses,Anti-gaspillage', 'Produit unité,Légumes,Légumes-racines',\n",
    "                                     'Produit unité,Légumes,Pommes de terre et autres tubercules', 'Produit unité,Légumes,Pommes de terre et autres tubercules,Anti-gaspillage', 'Produit unité,Légumes,Tomates, concombres et avocats',\n",
    "                                     'Produit unité,Légumes,Tomates, concombres et avocats,Anti-gaspillage', 'Produit unité,Légumes,Zucchinis, piments et aubergines', 'Produit unité,Légumes,Zucchinis, piments et aubergines,Anti-gaspillage'])\n",
    "\n",
    "categories['Fruits'] = categories['Produit unité,Fruits'] + categories['Produit unité,Fruits,Agrumes'] + categories['Produit unité,Fruits,Bananes, kiwi et fruits exotiques'] + categories['Produit unité,Fruits,Noel']\\\n",
    "+ categories['Produit unité,Fruits,Pommes et poires'] + categories['Produit unité,Fruits,Raisins et cerise'] \n",
    "categories = categories.drop(columns=['Produit unité,Fruits', 'Produit unité,Fruits,Agrumes', 'Produit unité,Fruits,Bananes, kiwi et fruits exotiques', 'Produit unité,Fruits,Noel', 'Produit unité,Fruits,Pommes et poires', 'Produit unité,Fruits,Raisins et cerise'])\n",
    "\n",
    "\n",
    "categories['Fish and Seafood'] = categories['Poisson,Produit unité,Produits de la mer'] + categories['Produit unité,Poissonnerie,Autres produits de la mer'] + categories['Produit unité,Poissonnerie,Autres produits de la mer,Noel'] + categories['Produit unité,Poissonnerie,Fruits de mer']\\\n",
    "+ categories['Produit unité,Poissonnerie,Fruits de mer,Noel'] + categories['Produit unité,Poissonnerie,Poissons congelés'] + categories['Produit unité,Poissonnerie,Poissons frais'] + categories['Produit unité,Produits de la mer,Autres produits de la mer'] + categories['Produit unité,Produits de la mer,Fruits de mer']\\\n",
    "+ categories['Produit unité,Produits de la mer,Poisson'] + categories['Autres produits de la mer,Produit unité,Produits de la mer'] + categories['Fruits de mer,Produit unité,Produits de la mer']\n",
    "categories = categories.drop(columns=['Poisson,Produit unité,Produits de la mer', 'Produit unité,Poissonnerie,Autres produits de la mer', 'Produit unité,Poissonnerie,Autres produits de la mer,Noel', 'Produit unité,Poissonnerie,Fruits de mer', 'Produit unité,Poissonnerie,Fruits de mer,Noel',\n",
    "                                      'Produit unité,Poissonnerie,Poissons congelés', 'Produit unité,Poissonnerie,Poissons frais', 'Produit unité,Produits de la mer,Autres produits de la mer', 'Produit unité,Produits de la mer,Fruits de mer', 'Produit unité,Produits de la mer,Poisson', 'Autres produits de la mer,Produit unité,Produits de la mer',\n",
    "                                     'Fruits de mer,Produit unité,Produits de la mer'])\n",
    "\n",
    "categories['Meat and charcuterie'] = categories['Autres viandes,Produit unité,Viandes'] + categories['Boeuf,Produit unité,Viandes'] + categories['Charcuterie,Pâté et rillette,Produit unité'] + categories['Charcuterie,Saucisses sèches et jambon,Produit unité'] + categories['Porc,Produit unité,Viandes']\\\n",
    "+ categories['Produit unité,Boucherie et Charcuterie,Autres viandes'] + categories['Produit unité,Boucherie et Charcuterie,Boeuf'] + categories['Produit unité,Boucherie et Charcuterie,Porc'] + categories['Produit unité,Boucherie et Charcuterie,Pâté et rillette'] + categories['Produit unité,Boucherie et Charcuterie,Pâté et rillette,Noel']\\\n",
    "+ categories['Produit unité,Boucherie et Charcuterie,Saucisses'] + categories['Produit unité,Boucherie et Charcuterie,Saucisses sèches et jambon'] +  categories['Produit unité,Boucherie et Charcuterie,Volaille'] +  categories['Saucisses,Produit unité,Viandes'] + categories['Produit unité,Viandes,Autres viandes']\\\n",
    "+ categories['Produit unité,Viandes,Boeuf'] + categories['Produit unité,Viandes,Porc'] +  categories['Produit unité,Viandes,Saucisses'] + categories['Produit unité,Viandes,Volaille'] + categories['Produit unité,Charcuterie,Pâté et rillette'] + categories['Produit unité,Charcuterie,Saucisses sèches et jambon'] + categories['Volaille,Produit unité,Viandes']\n",
    "\n",
    "categories = categories.drop(columns=['Autres viandes,Produit unité,Viandes', 'Boeuf,Produit unité,Viandes', 'Charcuterie,Pâté et rillette,Produit unité', 'Charcuterie,Saucisses sèches et jambon,Produit unité', 'Porc,Produit unité,Viandes', 'Produit unité,Boucherie et Charcuterie,Autres viandes', 'Produit unité,Boucherie et Charcuterie,Boeuf',\n",
    "                                     'Produit unité,Boucherie et Charcuterie,Porc', 'Produit unité,Boucherie et Charcuterie,Pâté et rillette', 'Produit unité,Boucherie et Charcuterie,Pâté et rillette,Noel', 'Produit unité,Boucherie et Charcuterie,Saucisses', 'Produit unité,Boucherie et Charcuterie,Saucisses sèches et jambon',\n",
    "                                     'Produit unité,Boucherie et Charcuterie,Volaille', 'Saucisses,Produit unité,Viandes', 'Produit unité,Viandes,Autres viandes', 'Produit unité,Viandes,Boeuf', 'Produit unité,Viandes,Porc', 'Produit unité,Viandes,Saucisses', 'Produit unité,Viandes,Volaille', 'Produit unité,Charcuterie,Pâté et rillette', 'Produit unité,Charcuterie,Saucisses sèches et jambon',\n",
    "                                     'Volaille,Produit unité,Viandes'])\n",
    "\n",
    "categories['Bread and baked goods'] = categories['Boulangerie,Pain,Produit unité'] + categories['Boulangerie,Viennoiserie,Produit unité'] + categories['Produit unité,Boulangerie et Pâtisserie,Autres pains'] + categories['Produit unité,Boulangerie et Pâtisserie,Autres pains,Noel'] + categories['Produit unité,Boulangerie et Pâtisserie,Pains']\\\n",
    "+ categories['Produit unité,Boulangerie et Pâtisserie,Pâtisserie et gâteaux'] + categories['Produit unité,Boulangerie et Pâtisserie,Pâtisserie et gâteaux,Noel'] + categories['Produit unité,Boulangerie et Pâtisserie,Tartes'] + categories['Produit unité,Boulangerie et Pâtisserie,Tartes,Noel'] + categories['Produit unité,Boulangerie et Pâtisserie,Viennoiserie']\\\n",
    "+ categories['Produit unité,Boulangerie,Pain'] + categories['Produit unité,Boulangerie,Viennoiserie'] + categories['Desserts,Pâtisserie et gâteau,Produit unité'] + categories['Desserts,Tarte,Produit unité'] + categories['Produit unité,Desserts,Pâtisserie et gâteau'] + categories['Produit unité,Desserts,Tarte']\n",
    "categories = categories.drop(columns=['Boulangerie,Pain,Produit unité', 'Boulangerie,Viennoiserie,Produit unité', 'Produit unité,Boulangerie et Pâtisserie,Autres pains', 'Produit unité,Boulangerie et Pâtisserie,Autres pains,Noel', 'Produit unité,Boulangerie et Pâtisserie,Pains', 'Produit unité,Boulangerie et Pâtisserie,Pâtisserie et gâteaux',\n",
    "                                      'Produit unité,Boulangerie et Pâtisserie,Pâtisserie et gâteaux,Noel', 'Produit unité,Boulangerie et Pâtisserie,Tartes', 'Produit unité,Boulangerie et Pâtisserie,Tartes,Noel', 'Produit unité,Boulangerie et Pâtisserie,Viennoiserie', 'Produit unité,Boulangerie,Pain', 'Produit unité,Boulangerie,Viennoiserie', 'Desserts,Pâtisserie et gâteau,Produit unité',\n",
    "                                     'Desserts,Tarte,Produit unité', 'Produit unité,Desserts,Pâtisserie et gâteau', 'Produit unité,Desserts,Tarte'])\n",
    "\n",
    "categories['Dairy and Cheese Products'] = categories['Fromage,Produit unité,Produits laitiers'] + categories['Fromage,Pâte ferme,Produit unité'] + categories['Fromage,Pâte molle,Produit unité'] + categories['Fromage,Pâte semi-ferme,Produit unité'] + categories['Kit,Fromagerie et Produits laitiers,Fromages à cuisiner'] + categories['Lait et Crème,Produit unité,Produits laitiers']\\\n",
    "+ categories['Produit unité,Fromage,Pâte ferme'] + categories['Produit unité,Fromage,Pâte molle'] + categories['Produit unité,Fromage,Pâte semi-ferme'] + categories['Produit unité,Fromagerie et Produits laitiers'] + categories['Produit unité,Fromagerie et Produits laitiers,Beurres'] + categories['Produit unité,Fromagerie et Produits laitiers,Cheddars']\\\n",
    "+ categories['Produit unité,Fromagerie et Produits laitiers,Fromages à cuisiner'] + categories['Produit unité,Fromagerie et Produits laitiers,Laits et crèmes'] + categories['Produit unité,Fromagerie et Produits laitiers,Planches'] + categories['Produit unité,Fromagerie et Produits laitiers,Pâte ferme'] + categories['Produit unité,Fromagerie et Produits laitiers,Pâte fraiche et pâte persillé']\\\n",
    "+ categories['Produit unité,Fromagerie et Produits laitiers,Pâte molle'] + categories['Produit unité,Fromagerie et Produits laitiers,Pâte molle,Noel'] + categories['Produit unité,Fromagerie et Produits laitiers,Pâte semi-ferme'] + categories['Produit unité,Fromagerie et Produits laitiers,Yogourts'] + categories['Beurre,Produit unité,Produits laitiers']\\\n",
    "+ categories['Produit unité,Produits laitiers,Beurre'] + categories['Produit unité,Produits laitiers,Lait et Crème'] + categories['Yogourt,Produit unité,Produits laitiers'] + categories['Produit unité,Produits laitiers,Yogourt']\n",
    "\n",
    "categories = categories.drop(columns=['Fromage,Produit unité,Produits laitiers', 'Fromage,Pâte ferme,Produit unité', 'Fromage,Pâte molle,Produit unité', 'Fromage,Pâte semi-ferme,Produit unité', 'Kit,Fromagerie et Produits laitiers,Fromages à cuisiner', 'Lait et Crème,Produit unité,Produits laitiers', 'Produit unité,Fromage,Pâte ferme', 'Produit unité,Fromage,Pâte molle',\n",
    "                                      'Produit unité,Fromage,Pâte semi-ferme', 'Produit unité,Fromagerie et Produits laitiers', 'Produit unité,Fromagerie et Produits laitiers,Beurres', 'Produit unité,Fromagerie et Produits laitiers,Cheddars', 'Produit unité,Fromagerie et Produits laitiers,Fromages à cuisiner', 'Produit unité,Fromagerie et Produits laitiers,Laits et crèmes',\n",
    "                                      'Produit unité,Fromagerie et Produits laitiers,Planches', 'Produit unité,Fromagerie et Produits laitiers,Pâte ferme', 'Produit unité,Fromagerie et Produits laitiers,Pâte fraiche et pâte persillé', 'Produit unité,Fromagerie et Produits laitiers,Pâte molle', 'Produit unité,Fromagerie et Produits laitiers,Pâte molle,Noel',\n",
    "                                      'Produit unité,Fromagerie et Produits laitiers,Pâte semi-ferme', 'Produit unité,Fromagerie et Produits laitiers,Yogourts', 'Beurre,Produit unité,Produits laitiers', 'Produit unité,Produits laitiers,Beurre', 'Produit unité,Produits laitiers,Lait et Crème', 'Yogourt,Produit unité,Produits laitiers', 'Produit unité,Produits laitiers,Yogourt'])\n",
    "\n",
    "categories['Prepared Meals and Dips'] = categories['Produit unité,Plats préparés,Autres Repas'] + categories['Produit unité,Plats préparés,Autres Repas,Garde-manger,Tofu et alternatives vegan'] + categories['Produit unité,Plats préparés,Pizzas, pâtés et quiches'] + categories['Produit unité,Plats préparés,Plats principaux'] + categories['Produit unité,Plats préparés,Soupes et trempettes']\\\n",
    "+ categories['Produit unité,Prêt-à-manger salé,Autres Repas'] +  categories['Produit unité,Prêt-à-manger salé,Pâté et Quiche'] + categories['Autre Repas,Prêt-à-manger salé,Produit unité'] + categories['Prêt-à-manger salé,Soupe,Produit unité'] + categories['Pâté et Quiche,Prêt-à-manger salé,Produit unité'] + categories['Produit unité,Prêt-à-manger salé,Trempettes']\\\n",
    "+ categories['Prêt-à-manger salé,Trempettes,Produit unité']\n",
    "\n",
    "categories = categories.drop(columns=['Produit unité,Plats préparés,Autres Repas', 'Produit unité,Plats préparés,Autres Repas,Garde-manger,Tofu et alternatives vegan', 'Produit unité,Plats préparés,Pizzas, pâtés et quiches', 'Produit unité,Plats préparés,Plats principaux', 'Produit unité,Plats préparés,Soupes et trempettes', 'Produit unité,Prêt-à-manger salé,Autres Repas',\n",
    "                                     'Produit unité,Prêt-à-manger salé,Pâté et Quiche', 'Autre Repas,Prêt-à-manger salé,Produit unité', 'Prêt-à-manger salé,Soupe,Produit unité', 'Pâté et Quiche,Prêt-à-manger salé,Produit unité', 'Produit unité,Prêt-à-manger salé,Trempettes', 'Prêt-à-manger salé,Trempettes,Produit unité'])\n",
    "\n",
    "categories['Plants, Flowers and Garden'] = categories['Bouquets,Plantes et fleurs,Produit unité'] + categories['Plantes et fleurs,Potager et Jardin,Produit unité'] + categories['Plantes et fleurs,Semis,Produit unité'] + categories['Plantes,Plantes et fleurs,Produit unité'] + categories['Produit unité,Plantes et fleurs,Bouquets']\\\n",
    "+ categories['Produit unité,Plantes et fleurs,Outils de jardinage'] + categories['Produit unité,Plantes et fleurs,Plantes'] + categories['Produit unité,Plantes et fleurs,Potager et Jardin'] + categories['Produit unité,Plantes et fleurs,Semis'] + categories['Outils de jardinage,Plantes et fleurs,Produit unité']\n",
    "\n",
    "categories = categories.drop(columns=['Bouquets,Plantes et fleurs,Produit unité', 'Plantes et fleurs,Potager et Jardin,Produit unité', 'Plantes et fleurs,Semis,Produit unité', 'Plantes,Plantes et fleurs,Produit unité', 'Produit unité,Plantes et fleurs,Bouquets', 'Produit unité,Plantes et fleurs,Outils de jardinage', 'Produit unité,Plantes et fleurs,Plantes',\n",
    "                                     'Produit unité,Plantes et fleurs,Potager et Jardin', 'Produit unité,Plantes et fleurs,Semis', 'Outils de jardinage,Plantes et fleurs,Produit unité'])\n",
    "\n",
    "categories['Pantry/Groceries'] = categories['Produit unité,Garde-manger,Olives et légumes marinés'] + categories['Produit unité,Garde-manger,Chips et craquelins'] + categories['Produit unité,Garde-manger,Chips et craquelins,Noel'] + categories['Produit unité,Garde-manger,Condiments'] + categories['Produit unité,Garde-manger,Condiments,Noel'] + categories['Produit unité,Garde-manger,Céréales et noix']\\\n",
    "+ categories['Produit unité,Garde-manger,Thés et cafés'] + categories['Produit unité,Garde-manger,Tofu et alternatives vegan'] + categories['Produit unité,Indispensables pour la cuisine,Ingrédients pour la cuisson,Garde-manger,Tofu et alternatives vegan'] + categories['Alternatives végé et vegan,Produit unité'] + categories['Condiments,Produit unité,Épiceries'] + categories['Produit unité,Épiceries,Olives']\\\n",
    "+ categories['Céréales,Produit unité,Épiceries'] + categories['Produit unité,Épiceries,Thé et Café'] + categories['Huile et Vinaigre,Produit unité,Épiceries'] + categories['Ingrédients pour la cuisson,Produit unité,Épiceries'] + categories['Olives,Produit unité,Épiceries'] + categories['Produit unité,Alternatives végé et vegan'] + categories['Produit unité,Indispensables pour la cuisine,Farines et sucres']\\\n",
    "+ categories['Produit unité,Indispensables pour la cuisine,Huiles et vinaigres'] + categories['Thé et Café,Produit unité,Épiceries'] + categories['Épices,Produit unité,Épiceries'] + categories['Produit unité,Épiceries'] + categories['Farine et sucre,Produit unité,Épiceries'] + categories['Produit unité,Indispensables pour la cuisine,Épices'] + categories['Produit unité,Épiceries,Céréales']\\\n",
    "+ categories['Produit unité,Indispensables pour la cuisine,Ingrédients pour la cuisson'] + categories['Produit unité,Épiceries,Huile et Vinaigre'] + categories['Produit unité,Épiceries,Épices'] + categories['Produit unité,Épiceries,Ingrédients pour la cuisson'] + categories['Produit unité,Pâtes, Sauces, Riz et Graines,Pâtes fraîches'] + categories['Produit unité,Pâtes, Sauces, Riz et Graines,Pâtes sèches']\\\n",
    "+ categories['Produit unité,Pâtes, Sauces, Riz et Graines,Riz, graines et légumineuses'] + categories['Produit unité,Pâtes, Sauces, Riz et Graines,Sauces'] + categories['Produit unité,Épiceries,Condiments'] + categories['Produit unité,Épiceries,Farine et sucre'] + categories['Produit unité,Épiceries,Pâtes et sauces'] + categories['Pâtes et sauces,Produit unité,Épiceries']\n",
    "\n",
    "categories = categories.drop(columns=['Produit unité,Garde-manger,Olives et légumes marinés', 'Produit unité,Garde-manger,Chips et craquelins', 'Produit unité,Garde-manger,Chips et craquelins,Noel', 'Produit unité,Garde-manger,Condiments', 'Produit unité,Garde-manger,Condiments,Noel', 'Produit unité,Garde-manger,Céréales et noix', 'Produit unité,Garde-manger,Thés et cafés',\n",
    "                                     'Produit unité,Garde-manger,Tofu et alternatives vegan', 'Produit unité,Indispensables pour la cuisine,Ingrédients pour la cuisson,Garde-manger,Tofu et alternatives vegan', 'Alternatives végé et vegan,Produit unité', 'Condiments,Produit unité,Épiceries', 'Produit unité,Épiceries,Olives', 'Céréales,Produit unité,Épiceries', 'Produit unité,Épiceries,Thé et Café',\n",
    "                                     'Huile et Vinaigre,Produit unité,Épiceries', 'Ingrédients pour la cuisson,Produit unité,Épiceries', 'Olives,Produit unité,Épiceries', 'Produit unité,Alternatives végé et vegan', 'Produit unité,Indispensables pour la cuisine,Farines et sucres', 'Produit unité,Indispensables pour la cuisine,Huiles et vinaigres', 'Thé et Café,Produit unité,Épiceries',\n",
    "                                     'Épices,Produit unité,Épiceries', 'Produit unité,Épiceries', 'Farine et sucre,Produit unité,Épiceries', 'Produit unité,Indispensables pour la cuisine,Épices', 'Produit unité,Épiceries,Céréales', 'Produit unité,Indispensables pour la cuisine,Ingrédients pour la cuisson',\n",
    "                                     'Produit unité,Épiceries,Huile et Vinaigre', 'Produit unité,Épiceries,Épices', 'Produit unité,Épiceries,Ingrédients pour la cuisson', 'Produit unité,Pâtes, Sauces, Riz et Graines,Pâtes fraîches', 'Produit unité,Pâtes, Sauces, Riz et Graines,Pâtes sèches', 'Produit unité,Pâtes, Sauces, Riz et Graines,Riz, graines et légumineuses',\n",
    "                                     'Produit unité,Pâtes, Sauces, Riz et Graines,Sauces', 'Produit unité,Épiceries,Condiments', 'Produit unité,Épiceries,Farine et sucre', 'Produit unité,Épiceries,Pâtes et sauces', 'Pâtes et sauces,Produit unité,Épiceries'])\n",
    "\n",
    "categories['Snacks'] = categories['Produit unité,Collations, Tartinades, Chocolats et Bonbons,Chocolats et bonbons,Noel'] + categories['Produit unité,Collations, Tartinades, Chocolats et Bonbons,Chocolats et bonbons'] + categories['Produit unité,Collations, Tartinades, Chocolats et Bonbons,Collations et biscuits'] + categories['Collations,Produit unité,Épiceries']\\\n",
    "+ categories['Confiseries,Produit unité,Épiceries'] + categories['Produit unité,Épiceries,Collations'] + categories['Produit unité,Épiceries,Confiseries']\n",
    "\n",
    "categories = categories.drop(columns=['Produit unité,Collations, Tartinades, Chocolats et Bonbons,Chocolats et bonbons,Noel', 'Produit unité,Collations, Tartinades, Chocolats et Bonbons,Chocolats et bonbons', 'Produit unité,Collations, Tartinades, Chocolats et Bonbons,Collations et biscuits', 'Collations,Produit unité,Épiceries', 'Confiseries,Produit unité,Épiceries', 'Produit unité,Épiceries,Collations',\n",
    "                                     'Produit unité,Épiceries,Confiseries'])\n",
    "\n",
    "categories['Bulk'] = categories['Céréales,Produit unité,Vrac'] + categories['Noix,Produit unité,Vrac'] + categories['Produit unité,Vrac,Céréales'] + categories['Produit unité,Vrac,Noix'] + categories['Produit unité,Vrac,Riz, graines et légumineuses'] + categories['Produit unité,Épices,Vrac'] + categories['Riz, graines et légumineuses,Produit unité,Vrac'] + categories['Épices,Produit unité,Vrac']\n",
    "\n",
    "categories = categories.drop(columns=['Céréales,Produit unité,Vrac', 'Noix,Produit unité,Vrac', 'Produit unité,Vrac,Céréales', 'Produit unité,Vrac,Noix', 'Produit unité,Vrac,Riz, graines et légumineuses', 'Produit unité,Épices,Vrac', 'Riz, graines et légumineuses,Produit unité,Vrac', 'Épices,Produit unité,Vrac'])\n",
    "\n",
    "categories['Other products'] = categories['Autre,Produit unité'] + categories['Produit unité,Autre'] + categories['Produit unité,Autres'] + categories['Produit unité,Autres,Noel'] + categories['Noel,Produit unité'] + categories['Produit unité,Noel'] + categories['Produit unité']\n",
    "\n",
    "categories = categories.drop(columns=['Autre,Produit unité', 'Produit unité,Autre', 'Produit unité,Autres', 'Produit unité,Autres,Noel', 'Noel,Produit unité', 'Produit unité,Noel', 'Produit unité'])\n",
    "\n",
    "categories['Drinks'] = categories['Boisson,Produit unité,Épiceries'] + categories['Produit unité,Boissons'] + categories['Produit unité,Boissons,Garde-manger'] + categories['Produit unité,Épiceries,Boisson']\n",
    "\n",
    "categories = categories.drop(columns=['Boisson,Produit unité,Épiceries', 'Produit unité,Boissons', 'Produit unité,Boissons,Garde-manger', 'Produit unité,Épiceries,Boisson'])\n",
    "\n",
    "categories['Baskets/Paniers'] = categories['Panier cadeau'] + categories['Non classé,Panier,Panier saisonnier'] + categories['Panier découverte,Panier'] + categories['Panier découverte,Panier'] + categories['Panier principal'] + categories['Panier,Panier additionnel'] + categories['Panier,Panier principal'] + categories['Panier,Panier principal,Panier personnalisable'] + categories['Paniers de la semaine,Panier additionnel']\\\n",
    "+ categories['Paniers de la semaine,Panier principal'] + categories['Paniers préconçus,Panier additionnel'] + categories['Paniers préconçus,Panier découverte'] + categories['Paniers préconçus,Panier principal'] + categories['Entreprise']\n",
    "\n",
    "categories = categories.drop(columns=['Panier cadeau', 'Non classé,Panier,Panier saisonnier', 'Panier découverte,Panier', 'Panier principal', 'Panier,Panier additionnel', 'Panier,Panier principal', 'Panier,Panier principal,Panier personnalisable', 'Paniers de la semaine,Panier additionnel', 'Paniers de la semaine,Panier principal', 'Paniers préconçus,Panier additionnel', 'Paniers préconçus,Panier découverte', \n",
    "                                      'Paniers préconçus,Panier principal', 'Entreprise'])\n",
    "\n",
    "categories['Beauty and Body Products'] = categories['Produit unité,Beauté'] + categories['Produit unité,Produits pour le corps'] + categories['Produits pour le corps,Produit unité']\n",
    "\n",
    "categories = categories.drop(columns=['Produit unité,Beauté', 'Produit unité,Produits pour le corps', 'Produits pour le corps,Produit unité'])\n",
    "\n",
    "categories['Eggs'] = categories['Oeufs,Produit unité,Épiceries'] + categories['Produit unité,Indispensables pour la cuisine,Oeufs'] + categories['Produit unité,Épiceries,Oeufs']\n",
    "\n",
    "categories = categories.drop(columns=['Oeufs,Produit unité,Épiceries', 'Produit unité,Indispensables pour la cuisine,Oeufs', 'Produit unité,Épiceries,Oeufs'])\n",
    "\n",
    "categories['Honey, Syrups, Jams, Nut Butters'] = categories['Miel, confiture et tartinade,Produit unité,Épiceries'] + categories['Produit unité,Collations, Tartinades, Chocolats et Bonbons,Miels, confitures et tartinades'] + categories['Produit unité,Épiceries,Miel, confiture et tartinade']\n",
    "\n",
    "categories = categories.drop(columns=['Miel, confiture et tartinade,Produit unité,Épiceries', 'Produit unité,Collations, Tartinades, Chocolats et Bonbons,Miels, confitures et tartinades', 'Produit unité,Épiceries,Miel, confiture et tartinade'])\n",
    "\n",
    "categories['Household Products'] = categories['Produit unité,Maison'] + categories['Produit unité,Produits ménagers'] + categories['Produits ménagers,Produit unité'] + categories['Produits ménagers,Produit unité'] \n",
    "categories = categories.drop(columns=['Produit unité,Maison', 'Produit unité,Produits ménagers', 'Produits ménagers,Produit unité'])\n",
    "\n",
    "#was instructed by contact at company to disregard gift cqrds. Some other categories are also not attached to prices -e.g. recette\n",
    "categories = categories.drop(columns=['Carte cadeau', 'Non classé', 'Abonnement panier,Abonnement', 'Abonnement produit,Abonnement', 'Compose ta recette', 'Recette'])\n",
    "print(categories.columns.tolist())\n",
    "#~200 categories to 18 categories!\n",
    "print(len(categories.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25ea2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>bienvenue20</th>\n",
       "      <th>soleil10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338278</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338279</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338280</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338281</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338282</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338283 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  bienvenue20  soleil10\n",
       "0       1            0         0\n",
       "1       1            0         0\n",
       "2       1            0         0\n",
       "3       1            0         0\n",
       "4       1            0         0\n",
       "...    ..          ...       ...\n",
       "338278  1            0         0\n",
       "338279  1            0         0\n",
       "338280  1            0         0\n",
       "338281  1            0         0\n",
       "338282  1            0         0\n",
       "\n",
       "[338283 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we may come back to questions around coupons so I will still create the categories in this workbook.\n",
    "df['coupons'] = df['Code de coupon']\n",
    "\n",
    "df['coupons'] = ['bienvenue20' if x == 'bienvenue20'\n",
    "                  else 'soleil10' if x == 'soleil10' else 0 for x in df['coupons']]\n",
    "\n",
    "coupons = pd.get_dummies(df['coupons'])\n",
    "coupons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2129699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attaching the 3 dataframes together for some later questions\n",
    "df = df.join(categories)\n",
    "df = df.join(coupons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6317a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[525140, 285775, 126786, 287166, 112346, 171993, 67242, 25683, 120391, 16621, 28117, 18124, 33817, 369522, 4721, 35636, 23310, 2241]\n",
      "{'Vegetables': 525140, 'Fruits': 285775, 'Fish and Seafood': 126786, 'Meat and charcuterie': 287166, 'Bread and baked goods': 112346, 'Dairy and Cheese Products': 171993, 'Prepared Meals and Dips': 67242, 'Plants, Flowers and Garden': 25683, 'Pantry/Groceries': 120391, 'Snacks': 16621, 'Bulk': 28117, 'Other products': 18124, 'Drinks': 33817, 'Baskets/Paniers': 369522, 'Beauty and Body Products': 4721, 'Eggs': 35636, 'Honey, Syrups, Jams, Nut Butters': 23310, 'Household Products': 2241}\n",
      "['Vegetables', 'Fruits', 'Fish and Seafood', 'Meat and charcuterie', 'Bread and baked goods', 'Dairy and Cheese Products', 'Prepared Meals and Dips', 'Plants, Flowers and Garden', 'Pantry/Groceries', 'Snacks', 'Bulk', 'Other products', 'Drinks', 'Baskets/Paniers', 'Beauty and Body Products', 'Eggs', 'Honey, Syrups, Jams, Nut Butters', 'Household Products']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver\\AppData\\Local\\Temp/ipykernel_8368/121874845.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Prix'] = df2['Prix du produit'] * df2['Quantité'] #multiplying the rows where there are multiple entries\n"
     ]
    }
   ],
   "source": [
    "#what categories of items predict higher value customers?\n",
    "\n",
    "#it doesn't make sense to use any rows where the product equals zero for the first question\n",
    "df2 = df[df['Prix du produit'] != 0]\n",
    "df2['Prix'] = df2['Prix du produit'] * df2['Quantité'] #multiplying the rows where there are multiple entries\n",
    "\n",
    "category_key = categories.columns.tolist()  #list of prodcut categories\n",
    "\n",
    "total_prices = []    \n",
    "\n",
    "    \n",
    "#for each category we sum all the price of all the rows that belong to it, and then append the sum to a list\n",
    "for x in category_key: \n",
    "    total_prices.append(sum(df2['Prix'].loc[(df2[x] > 0)]))\n",
    "\n",
    "#I forgot that floats aren't exact?!? So we round to ints\n",
    "total_prices = [int(x) for x in total_prices]\n",
    "\n",
    "#creating a dictionary with prices and items\n",
    "print(total_prices)   \n",
    "total_values = {}\n",
    "for key in category_key:\n",
    "    for value in total_prices:\n",
    "        total_values[key] = value\n",
    "        total_prices.remove(value)\n",
    "        break \n",
    "\n",
    "print(total_values)\n",
    "print(category_key)\n",
    "\n",
    "#sorting the values from highest to lowest. Vegetables was number 1, not surprising!\n",
    "import operator\n",
    "sorted_values = sorted(total_values.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3ab18f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97977, 45081, 20758, 50876, 18747, 30006, 12887, 2567, 28280, 2759, 0, 231, 5165, 27916, 474, 5499, 3368, 391]\n",
      "{'Vegetables': 97977, 'Fruits': 45081, 'Fish and Seafood': 20758, 'Meat and charcuterie': 50876, 'Bread and baked goods': 18747, 'Dairy and Cheese Products': 30006, 'Prepared Meals and Dips': 12887, 'Plants, Flowers and Garden': 2567, 'Pantry/Groceries': 28280, 'Snacks': 2759, 'Bulk': 0, 'Other products': 231, 'Drinks': 5165, 'Baskets/Paniers': 27916, 'Beauty and Body Products': 474, 'Eggs': 5499, 'Honey, Syrups, Jams, Nut Butters': 3368, 'Household Products': 391}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Vegetables', 97977),\n",
       " ('Meat and charcuterie', 50876),\n",
       " ('Fruits', 45081),\n",
       " ('Dairy and Cheese Products', 30006),\n",
       " ('Pantry/Groceries', 28280),\n",
       " ('Baskets/Paniers', 27916),\n",
       " ('Fish and Seafood', 20758),\n",
       " ('Bread and baked goods', 18747),\n",
       " ('Prepared Meals and Dips', 12887),\n",
       " ('Eggs', 5499),\n",
       " ('Drinks', 5165),\n",
       " ('Honey, Syrups, Jams, Nut Butters', 3368),\n",
       " ('Snacks', 2759),\n",
       " ('Plants, Flowers and Garden', 2567),\n",
       " ('Beauty and Body Products', 474),\n",
       " ('Household Products', 391),\n",
       " ('Other products', 231),\n",
       " ('Bulk', 0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thought they might want to see what this looks like in 2022\n",
    "\n",
    "df_2022 = df2.loc[(df2['Date commandé'] > '2022-01-01 00:00:00')]\n",
    "df_2022\n",
    "\n",
    "category_key_2022 = categories.columns.tolist()  #list of prodcut categories\n",
    "\n",
    "total_prices_2022 = []    \n",
    "\n",
    "    \n",
    "\n",
    "for x in category_key_2022: \n",
    "    total_prices_2022.append(sum(df_2022['Prix'].loc[(df_2022[x] > 0)]))\n",
    "\n",
    "\n",
    "total_prices_2022 = [int(x) for x in total_prices_2022]\n",
    "\n",
    "\n",
    "print(total_prices_2022)   \n",
    "total_values_2022 = {}\n",
    "for key in category_key_2022:\n",
    "    for value in total_prices_2022:\n",
    "        total_values_2022[key] = value\n",
    "        total_prices_2022.remove(value)\n",
    "        break \n",
    "\n",
    "print(total_values_2022)\n",
    "\n",
    "\n",
    "import operator\n",
    "sorted_values_2022 = sorted(total_values_2022.items(), key=operator.itemgetter(1))\n",
    "sorted_values_2022[:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa5483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "C:\\Users\\Oliver\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Total payé   R-squared:                       0.434\n",
      "Model:                            OLS   Adj. R-squared:                  0.434\n",
      "Method:                 Least Squares   F-statistic:                     976.0\n",
      "Date:                Thu, 19 May 2022   Prob (F-statistic):               0.00\n",
      "Time:                        14:38:32   Log-Likelihood:            -1.1905e+05\n",
      "No. Observations:               22900   AIC:                         2.381e+05\n",
      "Df Residuals:                   22881   BIC:                         2.383e+05\n",
      "Df Model:                          18                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "const                               40.7019      0.942     43.219      0.000      38.856      42.548\n",
      "Vegetables                           4.8929      1.024      4.777      0.000       2.885       6.901\n",
      "Fruits                              13.2972      0.900     14.778      0.000      11.534      15.061\n",
      "Fish and Seafood                    25.0395      0.725     34.546      0.000      23.619      26.460\n",
      "Meat and charcuterie                24.0641      0.670     35.935      0.000      22.752      25.377\n",
      "Bread and baked goods                9.5269      0.668     14.260      0.000       8.217      10.836\n",
      "Dairy and Cheese Products           16.3514      0.685     23.881      0.000      15.009      17.693\n",
      "Prepared Meals and Dips             19.3902      0.796     24.365      0.000      17.830      20.950\n",
      "Plants, Flowers and Garden          23.5653      1.184     19.905      0.000      21.245      25.886\n",
      "Pantry/Groceries                    20.1175      0.683     29.464      0.000      18.779      21.456\n",
      "Snacks                              14.3247      1.065     13.452      0.000      12.238      16.412\n",
      "Bulk                                -5.1426      0.829     -6.204      0.000      -6.767      -3.518\n",
      "Other products                      28.5332      1.972     14.469      0.000      24.668      32.398\n",
      "Drinks                               7.0402      0.781      9.012      0.000       5.509       8.572\n",
      "Baskets/Paniers                     15.4026      0.797     19.327      0.000      13.841      16.965\n",
      "Beauty and Body Products            12.1319      2.037      5.955      0.000       8.139      16.125\n",
      "Eggs                                 8.6363      0.719     12.017      0.000       7.228      10.045\n",
      "Honey, Syrups, Jams, Nut Butters    14.0597      1.083     12.979      0.000      11.936      16.183\n",
      "Household Products                  18.5643      2.599      7.143      0.000      13.470      23.658\n",
      "==============================================================================\n",
      "Omnibus:                     9077.078   Durbin-Watson:                   1.868\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            60837.952\n",
      "Skew:                           1.763   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.165   Cond. No.                         16.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#Here we are going to ask what product categories predict higher value orders.\n",
    "\n",
    "#For the Y we want just the order value which is the same for each row in a given order hence the 'mean' works\n",
    "Ymean = df2.groupby('No de commande').mean()\n",
    "Ymean = Ymean['Total payé']\n",
    "#For the X we want the presence/absence of the product clipped at 1 . I chose to do this rather than count the instances \n",
    "#as the business question is about inducing customers to buy a product category.\n",
    "Xmean = df2.groupby('No de commande').sum()\n",
    "Xmean = Xmean[['Vegetables', 'Fruits', 'Fish and Seafood', 'Meat and charcuterie', 'Bread and baked goods', \n",
    "      'Dairy and Cheese Products', 'Prepared Meals and Dips', 'Plants, Flowers and Garden', 'Pantry/Groceries', \n",
    "      'Snacks', 'Bulk', 'Other products', 'Drinks', 'Baskets/Paniers', 'Beauty and Body Products', 'Eggs', \n",
    "      'Honey, Syrups, Jams, Nut Butters', 'Household Products']]\n",
    "Xmean = Xmean.clip(upper=1)\n",
    "Xmean = sm.add_constant(Xmean)\n",
    "\n",
    "\n",
    "regr = sm.OLS(Ymean, Xmean).fit()\n",
    "\n",
    "print(regr.summary())\n",
    "#Not bad results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa1087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         No de commande   R-squared:                       0.020\n",
      "Model:                            OLS   Adj. R-squared:                  0.016\n",
      "Method:                 Least Squares   F-statistic:                     5.418\n",
      "Date:                Thu, 19 May 2022   Prob (F-statistic):           1.37e-11\n",
      "Time:                        14:38:40   Log-Likelihood:                -15893.\n",
      "No. Observations:                4363   AIC:                         3.182e+04\n",
      "Df Residuals:                    4346   BIC:                         3.193e+04\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "const                                5.2531      0.374     14.048      0.000       4.520       5.986\n",
      "Vegetables                          -0.4938      0.499     -0.989      0.323      -1.472       0.485\n",
      "Fruits                              -0.2449      0.454     -0.539      0.590      -1.135       0.645\n",
      "Fish and Seafood                     0.3241      0.390      0.830      0.407      -0.441       1.090\n",
      "Meat and charcuterie                -0.3198      0.355     -0.900      0.368      -1.016       0.377\n",
      "Bread and baked goods                0.0823      0.358      0.230      0.818      -0.619       0.783\n",
      "Dairy and Cheese Products            0.3260      0.358      0.911      0.362      -0.376       1.028\n",
      "Prepared Meals and Dips             -0.0627      0.429     -0.146      0.884      -0.903       0.778\n",
      "Plants, Flowers and Garden           0.0023      0.580      0.004      0.997      -1.134       1.139\n",
      "Pantry/Groceries                    -1.3469      0.372     -3.619      0.000      -2.077      -0.617\n",
      "Snacks                               0.0963      0.656      0.147      0.883      -1.190       1.382\n",
      "Drinks                              -0.5361      0.438     -1.223      0.221      -1.395       0.323\n",
      "Baskets/Paniers                      1.4985      0.339      4.414      0.000       0.833       2.164\n",
      "Beauty and Body Products             1.0550      1.089      0.969      0.333      -1.080       3.190\n",
      "Eggs                                 0.4829      0.380      1.269      0.204      -0.263       1.229\n",
      "Honey, Syrups, Jams, Nut Butters    -0.2275      0.550     -0.414      0.679      -1.305       0.850\n",
      "Household Products                  -0.1387      1.740     -0.080      0.936      -3.550       3.273\n",
      "==============================================================================\n",
      "Omnibus:                     3711.643   Durbin-Watson:                   2.039\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            96900.142\n",
      "Skew:                           4.068   Prob(JB):                         0.00\n",
      "Kurtosis:                      24.606   Cond. No.                         21.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[5.2531, -0.4938, -0.2449, 0.3241, -0.3198, 0.0823, 0.326, -0.0627, 0.0023, -1.3469, 0.0963, -0.5361, 1.4985, 1.055, 0.4829, -0.2275, -0.1387]\n"
     ]
    }
   ],
   "source": [
    "#now we are asking if product categories predict number of orders.\n",
    "\n",
    "#For the Y we want the number of orders, we keep one row for each order then group by email and count.\n",
    "df3 = df.drop_duplicates(subset=['No de commande'])\n",
    "df3 = df3.groupby('E-mail').count()\n",
    "\n",
    "df3 = df3.reset_index()\n",
    "\n",
    "#For the X we group by email and order so that we can sum product categories for each order\n",
    "df4 = df.groupby(['E-mail', 'No de commande']).sum()\n",
    "df4 = df4.reset_index()\n",
    "df4 = df4.drop_duplicates(['E-mail'])\n",
    "df4 = df4.reset_index()\n",
    "\n",
    "Ycount = df3['No de commande']\n",
    "\n",
    "#For the X we want the presence/absence of the product clipped at 1 . I chose to do this rather than count the instances \n",
    "#as the business question is about inducing customers to buy a product category.\n",
    "Xcount = df4[['Vegetables', 'Fruits', 'Fish and Seafood', 'Meat and charcuterie', 'Bread and baked goods', \n",
    "      'Dairy and Cheese Products', 'Prepared Meals and Dips', 'Plants, Flowers and Garden', 'Pantry/Groceries', \n",
    "      'Snacks', 'Drinks', 'Baskets/Paniers', 'Beauty and Body Products', 'Eggs', \n",
    "      'Honey, Syrups, Jams, Nut Butters', 'Household Products']]\n",
    "Xcount = Xcount.clip(upper=1)\n",
    "Xcount = sm.add_constant(Xcount)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import io \n",
    "\n",
    "regr_2 = sm.OLS(Ycount, Xcount).fit()\n",
    "\n",
    "#df5 = pd.read_table(regr_2.summary().as_csv())\n",
    "results2_summary = regr_2.summary()\n",
    "\n",
    "#This was just how I accessed the results as a dataframe so as to copy into my dash notebook.\n",
    "results_as_html = results2_summary.tables[1].as_html()\n",
    "df5 = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "df5 = df5.reset_index()\n",
    "print(regr_2.summary())\n",
    "print(list(df5['coef']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de8e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, we are going to attempt to predict whether a customer will order again or not using logistic regression!\n",
    "\n",
    "df5 = df.drop_duplicates(subset=['No de commande'])\n",
    "df5 = df5.groupby('E-mail').count()\n",
    "#This line encodes the number of orders into a 0/1 variable\n",
    "df5['repeat'] = [0 if x == 1 else 1 for x in df5['No de commande']]\n",
    "df5 = df5.reset_index()\n",
    "\n",
    "\n",
    "df6 = df.groupby(['E-mail', 'No de commande']).sum()\n",
    "df6 = df6.reset_index()\n",
    "df6 = df6.drop_duplicates(['E-mail'])\n",
    "df6 = df6.reset_index()\n",
    "\n",
    "Ylog = df5['repeat']\n",
    "\n",
    "#This time we don't clip the categories at 1, because we want to preserve as much information as possible.\n",
    "Xlog = df6[['Vegetables', 'Fruits', 'Fish and Seafood', 'Meat and charcuterie', 'Bread and baked goods', \n",
    "      'Dairy and Cheese Products', 'Prepared Meals and Dips', 'Plants, Flowers and Garden', 'Pantry/Groceries', \n",
    "      'Snacks', 'Drinks', 'Baskets/Paniers', 'Beauty and Body Products', 'Eggs', \n",
    "      'Honey, Syrups, Jams, Nut Butters', 'Household Products']]\n",
    "\n",
    "Xlog = sm.add_constant(Xlog)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xlog, Ylog, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(max_iter = 1000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d4885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.56\n",
      "[[154 435]\n",
      " [135 585]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "#Alas the accuracy is low...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e26dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.5763888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(89.18, 0.5, 'predicted label')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Below I played around with neural nets, didn't find anything better than the logistic regression. This honestly makes sense,\n",
    "#it would be strange to be able to predict too much of customer behaviour based on just a first order...\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "sns.set()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xlog, Ylog, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "nn = MLPClassifier(\n",
    "    hidden_layer_sizes=[50, 20, 10], \n",
    "    activation='relu', solver='adam', \n",
    "    alpha=0.0001, batch_size='auto', \n",
    "    learning_rate='constant', # adaptive\n",
    "    learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "    random_state=None, tol=0.0001, verbose=False, warm_start=False, \n",
    "    momentum=0.9, nesterovs_momentum=True, early_stopping=False, \n",
    "    validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "    n_iter_no_change=10, max_fun=15000)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "pred = nn.predict(X_test)\n",
    "\n",
    "print(f\"accuracy_score {accuracy_score(y_test, pred)}\")\n",
    "\n",
    "mat = confusion_matrix(y_test, pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fada9065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 17)               68        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                160       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 579\n",
      "Trainable params: 545\n",
      "Non-trainable params: 34\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "55/55 [==============================] - 1s 7ms/step - loss: 0.6996 - accuracy: 0.5175 - val_loss: 0.6873 - val_accuracy: 0.5719\n",
      "Epoch 2/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5116 - val_loss: 0.6876 - val_accuracy: 0.5556\n",
      "Epoch 3/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5469 - val_loss: 0.6874 - val_accuracy: 0.5588\n",
      "Epoch 4/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5451 - val_loss: 0.6864 - val_accuracy: 0.5588\n",
      "Epoch 5/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5455 - val_loss: 0.6864 - val_accuracy: 0.5588\n",
      "Epoch 6/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5459 - val_loss: 0.6850 - val_accuracy: 0.5588\n",
      "Epoch 7/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5455 - val_loss: 0.6847 - val_accuracy: 0.5588\n",
      "Epoch 8/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5459 - val_loss: 0.6852 - val_accuracy: 0.5588\n",
      "Epoch 9/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5459 - val_loss: 0.6851 - val_accuracy: 0.5588\n",
      "Epoch 10/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5459 - val_loss: 0.6851 - val_accuracy: 0.5588\n",
      "Epoch 11/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5459 - val_loss: 0.6848 - val_accuracy: 0.5588\n",
      "Epoch 12/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5459 - val_loss: 0.6850 - val_accuracy: 0.5588\n",
      "Epoch 13/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5459 - val_loss: 0.6855 - val_accuracy: 0.5588\n",
      "Epoch 14/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.5499 - val_loss: 0.6855 - val_accuracy: 0.5588\n",
      "Epoch 15/15\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5542 - val_loss: 0.6861 - val_accuracy: 0.5588\n",
      "Test loss: 0.0\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "input_shape = (17)\n",
    "batch_size = 50\n",
    "epochs = 15\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xlog, Ylog, test_size=0.3, random_state=0)\n",
    "\n",
    "# convert class vectors to one-hot class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "initializer = keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
    "# The actual neural net model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        # Input layer\n",
    "        keras.Input(shape=input_shape),\n",
    "        # Hidden layers\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Dense(15, activation=\"relu\"),\n",
    "        #layers.Dropout(rate = 0.5),\n",
    "        layers.Dense(10, activation=\"relu\"),\n",
    "        layers.Dense(5, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"relu\"),\n",
    "        layers.Dropout(rate = 0.5),\n",
    "        # Note the output shape is the number of classes\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "score = model.evaluate(X_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420ae0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
